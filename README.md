# Spark Data Pipeline Example
![Python](https://img.shields.io/badge/Python-3.x-blue)
![Apache Spark](https://img.shields.io/badge/Apache_Spark-3.5-red)
![Docker](https://img.shields.io/badge/Docker-Supported-blue)
![PySpark](https://img.shields.io/badge/PySpark-Ready-green)
![–ì—Ä–∞—Ñ–∏–∫](plots/revenue_by_status.png)
## üìä –ù–æ—É—Ç–±—É–∫
![Jupyter Notebook](https://img.shields.io/badge/Jupyter_Notebook-F37626?logo=jupyter&logoColor=white)

–ü—Ä–æ—Å—Ç–æ–π ETL-–ø–∞–π–ø–ª–∞–π–Ω –Ω–∞ PySpark —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π.

## –≠—Ç–∞–ø—ã
1. –ß—Ç–µ–Ω–∏–µ CSV
2. –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
3. –ê–≥—Ä–µ–≥–∞—Ü–∏—è: —Å—Ä–µ–¥–Ω—è—è –∑–∞—Ä–ø–ª–∞—Ç–∞ –ø–æ –æ—Ç–¥–µ–ª–∞–º
4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è

## –ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å

### 1. ETL (PowerShell)
```powershell
docker run -it --rm `
  -v "${PWD}:/work" `
  --entrypoint="" `
  apache/spark `
  /opt/spark/bin/spark-submit `
  /work/src/diagnose_json.py

